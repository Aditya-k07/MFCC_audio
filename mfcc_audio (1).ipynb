{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ae30ad-23a0-495f-b634-71abc550c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV loaded. Sample:\n",
      "   Unnamed: 0                                set_id  \\\n",
      "0           0  00026029e0--64991b6eef1fe70609d48edc   \n",
      "1           1  00026029e0--64991b72e0daf97163c09c66   \n",
      "2           2  00026029e0--64991b7fd94c0d5726dec353   \n",
      "3           3  00026029e0--64991b907f82d9763944eba2   \n",
      "4           4  00026029e0--64991bf2ffab6240f9f2418b   \n",
      "\n",
      "                                                text  gender  age country  \n",
      "0  The delicious aroma of freshly baked bread fil...    MALE   29      ZA  \n",
      "1  I enjoy taking long walks in the peaceful coun...  FEMALE   42      NG  \n",
      "2  The suspenseful novel kept me on the edge of m...  FEMALE   29      VN  \n",
      "3  They celebrated their anniversary with a roman...  FEMALE   20      PK  \n",
      "4  The diligent student earned top marks for her ...    MALE   30      PK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]C:\\Users\\Aditya Koul\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully extracted 68 samples.\n",
      "Feature shape: (68, 13) | Labels shape: (68,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_path = r\"C:\\Users\\Aditya Koul\\OneDrive\\Desktop\\CNN_beauty\\dataset_info.csv\"\n",
    "df = pd.read_csv(csv_path, sep=';') \n",
    "print(\" CSV loaded. Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "audio_base_path = r\"C:\\Users\\Aditya Koul\\OneDrive\\Desktop\\CNN_beauty\\files\"\n",
    "\n",
    "\n",
    "emotions = [\"euphoric\", \"joyfully\", \"sad\", \"surprised\"]\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "missing = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    set_id = row[\"set_id\"]\n",
    "    folder_path = os.path.join(audio_base_path, set_id)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        missing.append(set_id)\n",
    "        continue\n",
    "\n",
    "    for emotion in emotions:\n",
    "        file_path = os.path.join(folder_path, f\"{emotion}.wav\")\n",
    "        if not os.path.isfile(file_path):\n",
    "            missing.append(f\"{set_id}/{emotion}.wav\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "            mfcc_scaled = np.mean(mfcc.T, axis=0)  # ✅ This compresses the time axis\n",
    "            X.append(mfcc_scaled)\n",
    "            y.append(emotion)\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n Successfully extracted {len(X)} samples.\")\n",
    "print(f\"Feature shape: {np.array(X).shape} | Labels shape: {np.array(y).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a791-3c97-4961-8105-c1460401bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_frames = 100  # You can tune this (based on max length in your dataset)\n",
    "n_mfcc = 13\n",
    "\n",
    "def pad_mfcc(mfcc, maxlen=max_frames):\n",
    "    if mfcc.ndim != 2:\n",
    "        print(\" Warning: skipping malformed MFCC shape:\", mfcc.shape)\n",
    "        return np.zeros((n_mfcc, maxlen))\n",
    "    if mfcc.shape[1] > maxlen:\n",
    "        return mfcc[:, :maxlen]\n",
    "    else:\n",
    "        return np.pad(mfcc, ((0, 0), (0, maxlen - mfcc.shape[1])), mode='constant')\n",
    "\n",
    "\n",
    "X_padded = np.array([pad_mfcc(mfcc) for mfcc in X])\n",
    "X_padded = np.expand_dims(X_padded, axis=-1)         \n",
    "\n",
    "# Step 2: Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Step 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(13, max_frames, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Step 6: Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Decode predictions\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9314d7-03df-4b8d-aa30-1ab277c072aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "ids = []  # NEW: store set_ids for later plotting\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    set_id = row[\"set_id\"]\n",
    "    folder_path = os.path.join(audio_base_path, set_id)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue\n",
    "\n",
    "    for emotion in emotions:\n",
    "        file_path = os.path.join(folder_path, f\"{emotion}.wav\")\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "            mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "            X.append(mfcc_mean)\n",
    "            y.append(emotion)\n",
    "            ids.append(set_id)  # Track valid set_id\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e3c1e-8748-44cb-987a-312193322fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617f4c5-1c42-44b7-9a29-b635fbf5bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(4):\n",
    "    mfcc = librosa.feature.mfcc(y=librosa.load(os.path.join(audio_base_path, ids[i], f\"{y[i]}.wav\"), sr=None)[0], sr=sr, n_mfcc=13)\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    sns.heatmap(mfcc, cmap='viridis')\n",
    "    plt.title(f\"{y[i]} ({ids[i]})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"MFCC Coefficients\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d238ef7-3ff5-43ad-adbd-57392ceed732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE on the compressed MFCCs\n",
    "X_flat = np.array(X)  # Using the mean-compressed MFCCs\n",
    "tsne = TSNE(n_components=2, perplexity=15, random_state=42)\n",
    "X_proj = tsne.fit_transform(X_flat)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=X_proj[:, 0], y=X_proj[:, 1], hue=y, palette='bright')\n",
    "plt.title(\"t-SNE Projection of MFCC Features\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend(title='Emotion')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e119e-1d69-465c-ad3e-782a85c8ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fed0b6-3efe-4aef-a448-c528245512d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "samples = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    for _, row in df.iterrows():\n",
    "        set_id = row[\"set_id\"]\n",
    "        file_path = os.path.join(audio_base_path, set_id, f\"{emotion}.wav\")\n",
    "        if os.path.isfile(file_path):\n",
    "            samples[emotion] = file_path\n",
    "            break  # Take the first found valid file\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, (emotion, file_path) in enumerate(samples.items()):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    plt.subplot(2, 2, idx+1)\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(f\"Mel Spectrogram - {emotion}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
